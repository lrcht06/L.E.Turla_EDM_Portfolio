# Midterm Lab Task 2
This portfolio highlights the application of data normalization and cleaning in a transactional database. The dataset includes several related tables, each structured to optimize data organization and remove redundancy.

## STEP 1. Data Cleaning Process
Load the raw dataset from "Uncleaned_DS_jobs"
Adjust column width and height
Trim extra spaces and inconsistencies
Remove null values and fix "inf" errors
Eliminate duplicate records
Standardize salary estimates into min and max values
Normalize company size and location details

## STEP 2. Normalization
Apply First Normal Form (1NF)
Split tables according to Second Normal Form (2NF)
Implement Third Normal Form (3NF)
Structure data into a relational model

## STEP 3. Here is the screenshot of my output before I started data cleaning (see screenshot)
screenshot

## STEP 4. Here is the screenshot of my output after I started data cleaning (see screenshot)
screenshot

## STEP 5. Final Structured Tables
- "Sal By State ref" (Salary averages per state)
- "Sal By Role Type dup" (Salary averages per role type)
- "Sal By Role Size ref" (Salary averages per company size)
- "States" (State abbreviations and full names)

# Here is the Physical Data Model
screenshot
