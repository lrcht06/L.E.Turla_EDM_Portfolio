# Midterm Lab Task 2
This portfolio highlights the application of data normalization and cleaning in a transactional database. The dataset includes several related tables, each structured to optimize data organization and remove redundancy.

## STEP 1. Data Cleaning Process
Load the raw dataset from "Uncleaned_DS_jobs"
Adjust column width and height
Trim extra spaces and inconsistencies
Remove null values and fix "inf" errors
Eliminate duplicate records
Standardize salary estimates into min and max values
Normalize company size and location details

## STEP 2. Normalization
Apply First Normal Form (1NF)
Split tables according to Second Normal Form (2NF)
Implement Third Normal Form (3NF)
Structure data into a relational model

## STEP 3. Here is the screenshot of my output before I started data cleaning (see screenshot)
![screenshot](images/before.png)

## STEP 4. Here is the screenshot of my output after I started data cleaning (see screenshot)
![screenshot](images/Turla%20(CD).png)

## STEP 5. Here is the screenshot of the advanced editor code of power query steps (see screenshot)
![screenshot](images/Turla%20(AES).png)

## STEP 6. Final Structured Tables
### Sales By Role Type dup
![screenshot](images/Turla%20(SBRTd).png)
### Sales By Role Size ref
![screenshot](images/Turla%20(SBRSr).png)
### states
![screenshot](images/Turla%20(s).png)
### Sales By States ref
![screenshot](images/Turla%20(SBSr).png)

# Here is the Queries' Dependencies and References
![screenshot](images/Turla%20(QD).png)
